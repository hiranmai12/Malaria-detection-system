# -*- coding: utf-8 -*-
"""Projecttt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dPV3-u_fSvOqZSLru2e4kNKytBW61azr
"""

# from google.colab import files
# files.upload()   # choose kaggle.json file

# import zipfile

# with zipfile.ZipFile("../dataset/cell-images-for-detecting-malaria.zip", "r") as z:
#     z.extractall("../dataset")

# import os
# print(os.listdir("cell_images/cell_images"))

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# ----------------------------
# Load Dataset
# ----------------------------
import os

base_dir = "E:\\malariaproject\\backend\\dataset\\malariaimages\\cell_images\\cell_images"
infected_path = os.path.join(base_dir, "Parasitized")
uninfected_path = os.path.join(base_dir, "Uninfected")

print("Base Dir:", base_dir)
print("Infected Path:", infected_path, "Exists:", os.path.exists(infected_path))
print("Uninfected Path:", uninfected_path, "Exists:", os.path.exists(uninfected_path))

data = []
labels = []

# Infected images
for i in os.listdir(infected_path):
    try:
        img = cv2.imread(os.path.join(infected_path, i))
        img = Image.fromarray(img, 'RGB').resize((50,50))

        # Augmentations
        rotated45 = img.rotate(45)
        rotated75 = img.rotate(75)
        blur = Image.fromarray(cv2.blur(np.array(img), (10,10)))

        data.extend([np.array(img), np.array(rotated45), np.array(rotated75), np.array(blur)])
        labels.extend([1,1,1,1])
    except:
        continue

# Uninfected images
for i in os.listdir(uninfected_path):
    try:
        img = cv2.imread(os.path.join(uninfected_path, i))
        img = Image.fromarray(img, 'RGB').resize((50,50))

        rotated45 = img.rotate(45)
        rotated75 = img.rotate(75)

        data.extend([np.array(img), np.array(rotated45), np.array(rotated75)])
        labels.extend([0,0,0])
    except:
        continue

cells = np.array(data, dtype=np.float32)
labels = np.array(labels, dtype=np.int32)

# Normalize images
cells /= 255.0

# Shuffle dataset
indices = np.arange(cells.shape[0])
np.random.shuffle(indices)
cells = cells[indices]
labels = labels[indices]

print(f"Cells: {cells.shape} | Labels: {labels.shape}")

train_x, temp_x, train_y, temp_y = train_test_split(cells, labels, test_size=0.4, random_state=111)
eval_x, test_x, eval_y, test_y = train_test_split(temp_x, temp_y, test_size=0.5, random_state=111)

print(f"Train: {train_x.shape}, Eval: {eval_x.shape}, Test: {test_x.shape}")

# Plot label distribution
plt.figure(figsize=(15,5))
for idx, (y_set, name) in enumerate(zip([train_y, eval_y, test_y], ['Train', 'Validation', 'Test'])):
    plt.subplot(1,3,idx+1)
    sns.countplot(x=y_set)
    plt.title(f"{name} Labels")
plt.show()

def build_cnn():
    model = models.Sequential([
        layers.Input(shape=(50,50,3)),

        layers.Conv2D(32, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D(2,2),

        layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D(2,2),

        layers.Conv2D(128, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D(2,2),

        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(2, activation='softmax')
    ])
    return model

model = build_cnn()
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ----------------------------
history = model.fit(
    train_x, train_y,
    validation_data=(eval_x, eval_y),
    epochs=10,
    batch_size=32
)

# ----------------------------
# Evaluate Model
# ----------------------------
test_loss, test_acc = model.evaluate(test_x, test_y)
print(f"Test Accuracy: {test_acc:.4f}")

y_pred_probs = model.predict(test_x)
y_pred = np.argmax(y_pred_probs, axis=1)

print("Confusion Matrix:\n", confusion_matrix(test_y, y_pred))
print("\nClassification Report:\n", classification_report(test_y, y_pred))
print("Accuracy Score:", accuracy_score(test_y, y_pred))

class_names = ["Uninfected", "Infected"]

plt.figure(figsize=(15,9))
for n in range(49):
    r = np.random.randint(0, test_x.shape[0])
    plt.subplot(7,7,n+1)
    plt.imshow(test_x[r])
    plt.title(f"True: {class_names[test_y[r]]}\nPred: {class_names[y_pred[r]]}")
    plt.xticks([]); plt.yticks([])
plt.tight_layout()
plt.show()
# Save the trained CNN model for backend usage
model.save("malaria_model.h5")
print("âœ… Model saved as malaria_model.h5")
